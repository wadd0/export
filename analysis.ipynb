{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- Should probably use context channel in state https://langchain-ai.github.io/langgraph/how-tos/state-context-key/\n",
    "- Scratch pad for data, give ID and allow the LLM to reference - could this be a bunch of different dfs?\n",
    "- Should sql info be sent back in html? Is this the best format for an llm having been trained on html?\n",
    "- May need an llm to help format vega charts, spot errors etc\n",
    "- Create temp dataset, couple with vega spec\n",
    "\n",
    "**ISSUES**\n",
    "- Spending a lot of time generating a vega spec + plus wasting a lot of tokens\n",
    "- Consider vega-fusion and uuid-named view in duckdb, ask the llm to generate the vega spec without data https://vegafusion.io/duckdb.html#access-duckdb-tables\n",
    "- Can we get metadata about the results to generate the vega spec\n",
    "- How can we get an llm to analyse trends, when the only thing it can work with is text?\n",
    "- Struggles with time series analysis.\n",
    "- Need to be able to catch a follow up - would you like me to continue type message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_ROW_LIMIT = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import duckdb\n",
    "from duckdb import DuckDBPyConnection\n",
    "\n",
    "\n",
    "def build_db(data: dict[str, DataFrame]) -> DuckDBPyConnection:\n",
    "    \"\"\"Create an in-memory duckdb database from on or more pandas dataframes.\n",
    "\n",
    "    Dict format:\n",
    "\n",
    "        {\"table_name\": DataFrame}\n",
    "\n",
    "    Args:\n",
    "        data: Dict in the form {\"table_name\": DataFrame}.\n",
    "\n",
    "    Returns:\n",
    "        Connection to the duckdb database.\n",
    "    \"\"\"\n",
    "    connection = duckdb.connect(\":memory:\")\n",
    "\n",
    "    for table_name, dataframe in data.items():\n",
    "        connection.register(table_name, dataframe)\n",
    "\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def sql_db_list_tables(config: RunnableConfig) -> str:\n",
    "    \"\"\"Tool for getting tables names.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    Returns:\n",
    "        Comma-separated list of tables in the database.\n",
    "    \"\"\"\n",
    "    db: DuckDBPyConnection = config.get(\"configurable\", {}).get(\"db\")\n",
    "\n",
    "    return \", \".join(db.query(\"SHOW ALL TABLES\").df()[\"name\"])\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def sql_db_schema(table_names: str, config: RunnableConfig) -> str:\n",
    "    \"\"\"Get the schema and sample rows for the specified SQL tables. Be sure that\n",
    "    the tables actually exist by calling 'sql_db_list_tables' first!\n",
    "\n",
    "    Args:\n",
    "        table_names: Tables in a comma-separated list.\n",
    "\n",
    "    Returns:\n",
    "        The schema and sample rows for the specified SQL tables.\n",
    "    \"\"\"\n",
    "    db: DuckDBPyConnection = config.get(\"configurable\", {}).get(\"db\")\n",
    "    output = []\n",
    "    for table in table_names.split(\",\"):\n",
    "        schema = db.query(f\"SHOW {table}\").df().to_string(index=False)\n",
    "        sample = (\n",
    "            db.query(f\"SELECT * FROM {table} USING SAMPLE 5\")\n",
    "            .df()\n",
    "            .to_string(index=False)\n",
    "        )\n",
    "        output.append(f\"\\n\\nTABLE:{table}\\n\\n{schema}\\n\\n{sample}\")\n",
    "\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def sql_query_data(sql_query: str, config: RunnableConfig) -> str:\n",
    "    \"\"\"Input to this tool is a detailed and correct SQL query, output is a\n",
    "    result from the database. If the query is not correct, an error message\n",
    "    will be returned. If an error is returned, rewrite the query, check the\n",
    "    query, and try again.\n",
    "\n",
    "    Args:\n",
    "        sql_query: Correct and valid SQL query.\n",
    "\n",
    "    Returns:\n",
    "        Query results.\n",
    "    \"\"\"\n",
    "    db: DuckDBPyConnection = config.get(\"configurable\", {}).get(\"db\")\n",
    "\n",
    "    results = db.query(sql_query).df()\n",
    "    if results.shape[0] > QUERY_ROW_LIMIT:\n",
    "        raise ValueError(\"SQL query returned too many records.\")\n",
    "    return results.to_string(index=False)\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def chart_data(json_string: str) -> None:\n",
    "    \"\"\"Use this to generate a chart from a valid vega JSON chart specification.\n",
    "\n",
    "    Args:\n",
    "        json_string: A string containing a valid vega JSON chart specification.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        display(alt.Chart.from_json(json_string))\n",
    "    except Exception as e:\n",
    "        raise ValueError(\n",
    "            \"Unable to create chart from the input given, \"\n",
    "            \"please use valid vega chart specification.\"\n",
    "        )\n",
    "\n",
    "\n",
    "tools = [sql_db_list_tables, sql_db_schema, sql_query_data, chart_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b2e2dd152ac642dcb1e937b2bccab902.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b2e2dd152ac642dcb1e937b2bccab902.vega-embed details,\n",
       "  #altair-viz-b2e2dd152ac642dcb1e937b2bccab902.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b2e2dd152ac642dcb1e937b2bccab902\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b2e2dd152ac642dcb1e937b2bccab902\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b2e2dd152ac642dcb1e937b2bccab902\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-a0ae6b31095a718395e5a78d1e14f576\"}, \"mark\": \"point\", \"description\": \"A scatter plot with a custom dataset.\", \"encoding\": {\"x\": {\"field\": \"b\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"a\", \"type\": \"nominal\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"datasets\": {\"data-a0ae6b31095a718395e5a78d1e14f576\": [{\"a\": \"A\", \"b\": 28}, {\"a\": \"B\", \"b\": 55}, {\"a\": \"D\", \"b\": 91}, {\"a\": \"E\", \"b\": 81}, {\"a\": \"G\", \"b\": 19}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_json = \"\"\"\n",
    "{\n",
    "  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "  \"description\": \"A scatter plot with a custom dataset.\",\n",
    "  \"data\": {\n",
    "    \"values\": [\n",
    "      {\"a\": \"A\", \"b\": 28}, {\"a\": \"B\", \"b\": 55},\n",
    "      {\"a\": \"D\", \"b\": 91}, {\"a\": \"E\", \"b\": 81},\n",
    "      {\"a\": \"G\", \"b\": 19}\n",
    "    ]\n",
    "  },\n",
    "  \"mark\": \"point\",\n",
    "  \"encoding\": {\n",
    "    \"x\": {\"field\": \"b\", \"type\": \"quantitative\"},\n",
    "      \"y\": {\"field\": \"a\", \"type\": \"nominal\"}\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "chart_data.invoke(chart_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def should_continue(state: State) -> str:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system = f\"\"\"You are an agent designed to interact with a SQL database. Given an input \n",
    "question, create a syntactically correct duckdb query to run, then look at the results \n",
    "of the query and return the answer.\n",
    "\n",
    "Unless the user specifies a specific number of examples they wish to obtain, always \n",
    "limit your query to at most {QUERY_ROW_LIMIT} results. You can order the results by a \n",
    "relevant column to return the most interesting examples in the database.\n",
    "\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns \n",
    "given the question.\n",
    "\n",
    "You have access to tools for interacting with the database.\n",
    "Only use these tools. Only use the information returned by the tools to construct your \n",
    "final answer. If you get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "If the question does not seem related to the database, or you cannot answer the question, \n",
    "return \"I don't know\" as the answer.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=system),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "\n",
    "def build_db(data: dict[str, pd.DataFrame]) -> duckdb.DuckDBPyConnection:\n",
    "\n",
    "    connection = duckdb.connect(\":memory:\")\n",
    "\n",
    "    for table_name, dataframe in data.items():\n",
    "        connection.register(table_name, dataframe)\n",
    "\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/0n4322_n2n3_pyh0fz_zwjzh0000gn/T/ipykernel_70929/4165688245.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"saledate\"] = pd.to_datetime(df[\"saledate\"], errors=\"coerce\", utc=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 558799 entries, 0 to 558836\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count   Dtype              \n",
      "---  ------        --------------   -----              \n",
      " 0   year          558799 non-null  int64              \n",
      " 1   make          558799 non-null  object             \n",
      " 2   model         558799 non-null  object             \n",
      " 3   trim          558799 non-null  object             \n",
      " 4   body          558799 non-null  object             \n",
      " 5   transmission  558799 non-null  object             \n",
      " 6   vin           558799 non-null  object             \n",
      " 7   state         558799 non-null  object             \n",
      " 8   condition     558799 non-null  float64            \n",
      " 9   odometer      558799 non-null  float64            \n",
      " 10  color         558799 non-null  object             \n",
      " 11  interior      558799 non-null  object             \n",
      " 12  seller        558799 non-null  object             \n",
      " 13  mmr           558799 non-null  float64            \n",
      " 14  sellingprice  558799 non-null  float64            \n",
      " 15  saledate      558799 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), float64(4), int64(1), object(10)\n",
      "memory usage: 72.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"car_prices.csv\")\n",
    "df.loc[:, \"make\"] = df.loc[:, [\"make\"]].fillna(df[\"make\"].mode()[0])\n",
    "df.loc[:, \"model\"] = df.loc[:, [\"model\"]].fillna(df[\"model\"].mode()[0])\n",
    "df.loc[:, \"body\"] = df.loc[:, [\"body\"]].fillna(df[\"body\"].mode()[0])\n",
    "df.loc[:, \"trim\"] = df.loc[:, [\"trim\"]].fillna(df[\"trim\"].mode()[0])\n",
    "df.loc[:, \"color\"] = df.loc[:, [\"color\"]].fillna(df[\"color\"].mode()[0])\n",
    "df.loc[:, \"interior\"] = df.loc[:, [\"interior\"]].fillna(df[\"interior\"].mode()[0])\n",
    "df.loc[:, \"transmission\"] = df.loc[:, [\"transmission\"]].fillna(\n",
    "    df[\"transmission\"].mode()[0]\n",
    ")\n",
    "\n",
    "df.loc[:, \"condition\"] = df.loc[:, [\"condition\"]].fillna(df[\"condition\"].mean())\n",
    "df.loc[:, \"odometer\"] = df.loc[:, [\"odometer\"]].fillna(df[\"odometer\"].mean())\n",
    "df.loc[:, \"mmr\"] = df.loc[:, [\"mmr\"]].fillna(df[\"mmr\"].mean())\n",
    "df[\"saledate\"] = pd.to_datetime(df[\"saledate\"], errors=\"coerce\", utc=True)\n",
    "df.dropna(subset=[\"sellingprice\", \"saledate\"], axis=\"rows\", inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"db\": build_db({\"car_sales\": df}),\n",
    "        \"recursion_limit\": 25,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_uWp1GgyvmzuYTeU5wvuSiDYl)\n",
      " Call ID: call_uWp1GgyvmzuYTeU5wvuSiDYl\n",
      "  Args:\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "car_sales\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_h000bcTjP2GrADeBxjcAg4YH)\n",
      " Call ID: call_h000bcTjP2GrADeBxjcAg4YH\n",
      "  Args:\n",
      "    table_names: car_sales\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "\n",
      "TABLE:car_sales\n",
      "\n",
      " column_name              column_type null  key default extra\n",
      "        year                   BIGINT  YES None    None  None\n",
      "        make                  VARCHAR  YES None    None  None\n",
      "       model                  VARCHAR  YES None    None  None\n",
      "        trim                  VARCHAR  YES None    None  None\n",
      "        body                  VARCHAR  YES None    None  None\n",
      "transmission                  VARCHAR  YES None    None  None\n",
      "         vin                  VARCHAR  YES None    None  None\n",
      "       state                  VARCHAR  YES None    None  None\n",
      "   condition                   DOUBLE  YES None    None  None\n",
      "    odometer                   DOUBLE  YES None    None  None\n",
      "       color                  VARCHAR  YES None    None  None\n",
      "    interior                  VARCHAR  YES None    None  None\n",
      "      seller                  VARCHAR  YES None    None  None\n",
      "         mmr                   DOUBLE  YES None    None  None\n",
      "sellingprice                   DOUBLE  YES None    None  None\n",
      "    saledate TIMESTAMP WITH TIME ZONE  YES None    None  None\n",
      "\n",
      " year      make      model trim     body transmission               vin state  condition  odometer color interior                       seller     mmr  sellingprice                  saledate\n",
      " 2011 Chevrolet     Malibu  LT1    sedan    automatic 1g1zc5e16bf281355    va       29.0   31825.0   red    black  wells fargo dealer services 10300.0       10600.0 2015-06-02 20:30:00+01:00\n",
      " 2012     Dodge    Avenger  SXT    Sedan    automatic 1c3cdzcb5cn154573    tn       34.0   62993.0   red     gray           santander consumer  8725.0        9500.0 2015-02-09 18:30:00+00:00\n",
      " 2007      Ford Expedition  XLT      SUV    automatic 1fmfu15527la46829    fl       19.0  118004.0  gold    brown innovate loan servicing corp  7650.0        5900.0 2014-12-18 07:01:00+00:00\n",
      " 2014     Lexus     ES 350 Base    Sedan    automatic jthbk1gg2e2109212    pa       49.0    8660.0 white    black          adcock brothers inc 31100.0       32600.0 2015-01-15 17:00:00+00:00\n",
      " 2013    Nissan   Frontier   SV Crew Cab    automatic 1n6ad0ev4dn716371    fl       24.0   44829.0 white     gray        the hertz corporation 19650.0       19400.0 2015-06-02 20:40:00+01:00\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "questions = {\n",
    "    1: \"Which model of car had the highest growth in sales between 2015 and 2016?\",\n",
    "    2: \"Draw a chart of sales in 2014 for the top 10 models.\",\n",
    "    3: \"Show me the trend in Toyota sales by year. Include a chart.\",\n",
    "    4: (\n",
    "        \"Show me year on year sales movements (movement is year - prior year) from the \"\n",
    "        \"year 2000 for toyota, include a chart. Ensure year is ordinal.\"\n",
    "    ),\n",
    "    6: \"Show sales volumes by brand (vehicles not sales proce) by year.\",\n",
    "    7: \"Examine sales trends from 2000 to 2005, do all brands have the same trend?\",\n",
    "    8: \"Examine sales trends from 2000 to 2005, do all brands have the same trend? Consider multiple sql statements.\",\n",
    "    9: \"Are car sales seasonal? Does this vary by year or state?\",\n",
    "}\n",
    "\n",
    "input = prompt_template.invoke({\"question\": questions[8]})\n",
    "\n",
    "for event in graph.stream(input, config=config):\n",
    "    value = next(iter(event.values()))\n",
    "    print(value[\"messages\"][0].pretty_print())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
